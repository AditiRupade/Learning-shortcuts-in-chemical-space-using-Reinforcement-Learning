{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3dd6f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d1819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maze and goal state\n",
    "maze = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 2]\n",
    "])\n",
    "goal_state = (4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03153688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the actions and their corresponding changes in position\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "action_deltas = [(-1, 0), (1, 0), (0, -1), (0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3957b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of episodes to train the agent\n",
    "num_episodes = 1000\n",
    "\n",
    "# Define the learning rate and discount factor\n",
    "alpha = 0.5\n",
    "gamma = 0.9\n",
    "\n",
    "# Define the epsilon value for the epsilon-greedy policy\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598b56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Q-matrix with zeros\n",
    "Q = np.zeros((maze.shape[0], maze.shape[1], 4))\n",
    "\n",
    "# Define the rewards for each state\n",
    "rewards = {\n",
    "    0: -1,   # Maze cell\n",
    "    1: -1,   # Wall\n",
    "    2: 10    # Goal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26305fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to choose an action using the epsilon-greedy policy\n",
    "def choose_action(state):\n",
    "    if np.random.random() < epsilon:\n",
    "        # Choose a random action\n",
    "        return actions[np.random.randint(0, len(actions))]\n",
    "    else:\n",
    "        # Choose the action with the highest Q-value\n",
    "        return actions[np.argmax(Q[state[0], state[1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfc0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to update the Q-value using SARSA\n",
    "def update_q_value(state, action, reward, next_state, next_action):\n",
    "    # Calculate the TD error\n",
    "    td_error = reward + gamma * Q[next_state[0], next_state[1], actions.index(next_action)] - Q[state[0], state[1], actions.index(action)]\n",
    "    \n",
    "    # Update the Q-value for the current state and action\n",
    "    Q[state[0], state[1], actions.index(action)] += alpha * td_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2973166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the colors to use\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "YELLOW = (255,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5726a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to simulate an episode\n",
    "def run_episode(training=True):\n",
    "    # Choose a random starting state that is not the goal state\n",
    "    state = (np.random.randint(0, maze.shape[0]), np.random.randint(0, maze.shape[1]))\n",
    "\n",
    "    while state == goal_state:\n",
    "        state = (np.random.randint(0, maze.shape[0]), np.random.randint(0, maze.shape[1]))\n",
    "    \n",
    "    init = state\n",
    "    \n",
    "    # Clear the screen\n",
    "    screen.fill(WHITE)\n",
    "    \n",
    "    # Draw the maze and the goal\n",
    "    for i in range(maze.shape[0]):\n",
    "        for j in range(maze.shape[1]):\n",
    "            rect = pygame.Rect(j*cell_size, i*cell_size, cell_size, cell_size)\n",
    "            if i == init[0] and j == init[1]: #Start cell\n",
    "                pygame.draw.rect(screen, YELLOW, rect)\n",
    "                pygame.draw.circle(screen, RED, (state[1]*cell_size+25,state[0]*cell_size+25), 5)\n",
    "            elif maze[i,j] == 0:  # Maze cell\n",
    "                pygame.draw.rect(screen, BLACK, rect)\n",
    "            elif maze[i,j] == 1:  #Wall\n",
    "                pygame.draw.rect(screen, BLUE, rect)\n",
    "            elif maze[i,j] == 2: #Goal\n",
    "                pygame.draw.rect(screen, GREEN, rect)\n",
    "    \n",
    "    # Choose the first action using an epsilon-greedy policy\n",
    "    action = choose_action(state)\n",
    "    \n",
    "    # Initialize the total reward\n",
    "    total_reward = 0\n",
    "    \n",
    "    # Repeat until the goal state is reached\n",
    "    while state != goal_state:\n",
    "        # Move to the next state\n",
    "        delta = action_deltas[actions.index(action)]\n",
    "        next_state = (state[0]+delta[0], state[1]+delta[1])\n",
    "        \n",
    "        # If the next state is outside the maze, set it to the current state\n",
    "        if next_state[0] < 0 or next_state[0] >= maze.shape[0] or next_state[1] < 0 or next_state[1] >= maze.shape[1]:\n",
    "            next_state = state\n",
    "        \n",
    "        # Get the reward for the next state\n",
    "        reward = rewards[maze[next_state[0], next_state[1]]]\n",
    "    \n",
    "        # Update the Q-value using SARSA\n",
    "        next_action = choose_action(next_state)\n",
    "        if training == True:\n",
    "            update_q_value(state, action, reward, next_state, next_action)\n",
    "\n",
    "        # Update the total reward and current state and action\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "\n",
    "        # Draw the current state of the agent\n",
    "        for i in range(maze.shape[0]):\n",
    "            for j in range(maze.shape[1]):\n",
    "                if i == state[0] and j == state[1]: #Next cell\n",
    "                    pygame.draw.circle(screen, RED, (state[1]*cell_size+25,state[0]*cell_size+25), 5)\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b1e56bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -172\n",
      "Episode 2: Total Reward = -2\n",
      "Episode 3: Total Reward = 2\n",
      "Episode 4: Total Reward = -5\n",
      "Episode 5: Total Reward = -17\n",
      "Episode 6: Total Reward = -47\n",
      "Episode 7: Total Reward = 7\n",
      "Episode 8: Total Reward = 0\n",
      "Episode 9: Total Reward = 0\n",
      "Episode 10: Total Reward = 9\n",
      "Episode 11: Total Reward = 5\n",
      "Episode 12: Total Reward = 10\n",
      "Episode 13: Total Reward = 9\n",
      "Episode 14: Total Reward = 10\n",
      "Episode 15: Total Reward = 3\n",
      "Episode 16: Total Reward = 6\n",
      "Episode 17: Total Reward = 9\n",
      "Episode 18: Total Reward = 9\n",
      "Episode 19: Total Reward = -1\n",
      "Episode 20: Total Reward = -1\n",
      "Episode 21: Total Reward = 9\n",
      "Episode 22: Total Reward = 5\n",
      "Episode 23: Total Reward = 6\n",
      "Episode 24: Total Reward = -6\n",
      "Episode 25: Total Reward = 7\n",
      "Episode 26: Total Reward = 9\n",
      "Episode 27: Total Reward = 8\n",
      "Episode 28: Total Reward = 4\n",
      "Episode 29: Total Reward = 6\n",
      "Episode 30: Total Reward = 4\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "#Define the size of each cell in the maze and the size of the window\n",
    "cell_size = 50\n",
    "window_size = (maze.shape[1]*cell_size, maze.shape[0]*cell_size)\n",
    "\n",
    "#Create the window\n",
    "screen = pygame.display.set_mode(window_size)\n",
    "pygame.display.set_caption(\"Maze\")\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Train the agent for the specified number of episodes\n",
    "for i in range(30):\n",
    "    total_reward = run_episode()\n",
    "    \n",
    "    # Print the total reward for the episode\n",
    "    print(f\"Episode {i+1}: Total Reward = {total_reward}\")\n",
    "    \n",
    "    # Update the Pygame window\n",
    "    pygame.display.flip()\n",
    "    \n",
    "    # Pause briefly to allow the user to see the visualization\n",
    "    #pygame.time.wait(3000)\n",
    "\n",
    "# Wait for the user to close the Pygame window\n",
    "while True:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f93e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 10\n",
      "Episode 2: Total Reward = -46\n",
      "Episode 3: Total Reward = 9\n",
      "Episode 4: Total Reward = 10\n",
      "Episode 5: Total Reward = 7\n",
      "Episode 6: Total Reward = 3\n",
      "Episode 7: Total Reward = 9\n",
      "Episode 8: Total Reward = -118\n",
      "Episode 9: Total Reward = -150\n",
      "Episode 10: Total Reward = 10\n"
     ]
    }
   ],
   "source": [
    "#Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "#Define the size of each cell in the maze and the size of the window\n",
    "cell_size = 50\n",
    "window_size = (maze.shape[1]*cell_size, maze.shape[0]*cell_size)\n",
    "\n",
    "#Create the window\n",
    "screen = pygame.display.set_mode(window_size)\n",
    "pygame.display.set_caption(\"Maze\")\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Test the agent for the specified number of episodes\n",
    "for i in range(10):\n",
    "    total_reward = run_episode(training=False)\n",
    "    \n",
    "    # Print the total reward for the episode\n",
    "    print(f\"Episode {i+1}: Total Reward = {total_reward}\")\n",
    "    \n",
    "    # Update the Pygame window\n",
    "    pygame.display.flip()\n",
    "    \n",
    "    # Pause briefly to allow the user to see the visualization\n",
    "    pygame.time.wait(3000)\n",
    "\n",
    "# Wait for the user to close the Pygame window\n",
    "while True:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45a6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
